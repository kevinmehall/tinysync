#!/usr/bin/env python
import sys
import hashlib
import os
import fnmatch
from urlparse import urlparse
from optparse import OptionParser
import paramiko
paramiko.util.log_to_file('/tmp/paramiko.log')

DIGEST_NAME = '.tinyupload_digest'
CONFIG_NAME = '.tinyupload_config'

class Backend:
	pass	

class LocalBackend(Backend):
	def __init__(self, path):
		self.path = path

	def connect(self):
		if not os.path.exists(self.path):
			print "Creating remote base directory"
			os.mkdir(self.path)
			
	def done(self):
		pass
		
	def get_digest(self):
		try:
			return open(os.path.join(self.path, DIGEST_NAME), 'rt').read()
		except IOError:
			return ''
			
	def put_digest(self, digest):
		open(os.path.join(self.path, DIGEST_NAME), 'wt').write(digest)
			
	def put_file(self, localfile, path):
		f = open(os.path.join(self.path, path), 'wb')
		f.write(open(localfile, 'rb').read())
		f.close()
		
	def mkdir(self, path):
		os.mkdir(os.path.join(self.path, path))
		
	def delete_dir(self, path):
		os.rmdir(os.path.join(self.path, path))
		
	def delete_file(self, path):
		os.unlink(os.path.join(self.path, path))

class SFTPBackend(Backend):
	def __init__(self, uri):
		self.uri = uri
		
	def connect(self):
		self.transport = paramiko.Transport(self.uri.hostname)
		agent = paramiko.Agent()
		keys = agent.get_keys()
		if len(keys) != 0:
   			self.transport.connect()
			for key in keys:
				try:
					self.transport.auth_publickey(self.uri.username, key)
				except:
					pass
				if self.transport.is_authenticated():
					break
		if not self.transport.is_authenticated():
			self.transport.auth_password(self.uri.username, self.uri.password)
		self.sftp = paramiko.SFTPClient.from_transport(self.transport)
		try:
			self.sftp.mkdir(self.uri.path)
			print "Creating remote base directory"
		except:
			pass
		self.sftp.chdir(self.uri.path)
		
	def done(self):
		self.sftp.close()
		self.transport.close()
		
	def get_digest(self):
		try:
			return self.sftp.open(DIGEST_NAME).read()
		except:
			return ''
			
	def put_digest(self, digest):
		f = self.sftp.open(DIGEST_NAME, 'w')
		f.write(digest)
		f.close()
			
	def put_file(self, localfile, path):
		self.sftp.put(localfile, path)
		
	def mkdir(self, path):
		self.sftp.mkdir(path)
		
	def delete_dir(self, path):
		self.sftp.rmdir(path)
		
	def delete_file(self, path):
		self.sftp.unlink(path)

def backend_from_uri(uri):
	uri  = urlparse(uri)
	if uri.scheme == 'file':
		return LocalBackend(uri.path)
	elif uri.scheme == 'sftp':
		return SFTPBackend(uri)
	else:
		raise TypeError("Unknown URI scheme")

class TinyUpload:
	@classmethod		
	def make_digest(self, m):
		l=[]
		for path in m:
			l.append("%s  %s"%(m[path], path))
		return '\n'.join(l)
	
	@classmethod		
	def parse_digest(self, c):
		r = {}
		for line in c.split('\n'):
			if not line: continue
			sha1, path =  line.split('  ')
			r[path] = sha1
		return r
	
	
	def __init__(self, path='.'):
		self.path = path
		self.exclude = ['.tinyupload_config', '.bzr', '.git', '*~']
		
	def is_excluded(self, path):
		for rule in self.exclude:
			if fnmatch.fnmatch(path, rule):
				return True
		return False

	def walk_file(self, path):
		#print 'walking', path
		if self.is_excluded(path):
			return False
		
		if os.path.isdir(path):
			sha1 = 'dir'
		else:
			h = hashlib.new('sha1')
			f = open(os.path.join(self.path, path), 'rb')
			while True:
				x = f.read(1024*1024)
				if not x: break
				h.update(x)
			sha1 = h.hexdigest()
			
		self.local[path] = sha1
		return sha1
		
				
	def walk_local(self):
		self.local = {}
		for dirpath, dirnames, filenames in os.walk(self.path):
			dirname = dirpath[len(self.path)+1:]
			for i in filenames:
				self.walk_file(os.path.join(dirname, i))
			for i in dirnames[:]:
				if not self.walk_file(os.path.join(dirname, i)):
					dirnames.remove(i)
				
		return self.local
		
	def sync(self, backend, dryrun = False, force_full=False):
		local = self.walk_local()
		backend.connect()
		
		if force_full:
			remote = {}
		else:
			remote = self.parse_digest(backend.get_digest())
		
		added = updated = deleted = total = 0
		
		for i in remote:
			if i not in local:
				print "Deleting %s"%(i)
				deleted += 1
				
				if dryrun: continue
				
				if remote[i] == 'dir':
					backend.delete_dir(i)
				else:
					backend.delete_file(i)
				
		
		for i in sorted(local):
			total += 1
			if i not in remote:
				print "Adding   %s"%(i)
				added += 1
			elif local[i] != remote[i]:
				print "Updating %s"%(i)
				updated += 1
			else:
				continue
				
			if dryrun: continue
			
			if local[i] == 'dir':
				if i in remote:
					backend.delete_file(i)
				backend.mkdir(i)
			else:
				if i in remote and remote[i] == 'dir':
					backend.delete_dir(i)
				backend.put_file(os.path.join(self.path, i), i)
				
		if added+updated+deleted and not (dryrun is True):
			backend.put_digest(self.make_digest(local))
		backend.done()
		
		if dryrun == 'digest-only':
			print "UPDATING DIGEST: ",
		elif dryrun:
			print "DRY RUN: ",
		print "Synchronized %i files. (%i added; %i updated; %i deleted)" %(total, added, updated, deleted)
		
	def add_exclude_rule(self, rule):
		f = open(os.path.join(self.path, CONFIG_NAME), 'at')
		f.write('\nexclude %s'%(rule))
		f.close()
		
	def add_location(self, name, uri):
		f = open(os.path.join(self.path, CONFIG_NAME), 'at')
		f.write('\n%s = %s'%(name, uri))
		f.close()
		
	def read_config(self, location=None):
		try:
			cfg = open(os.path.join(self.path, CONFIG_NAME), 'rt')
		except IOError:
			print "Config file %s not found"%CONFIG_NAME
			return
		
		uri = None
		for line in cfg:
			if not line.strip(): continue
			if line.startswith('exclude '):
				self.exclude.append(line[len('exclude '):].strip())
			else:
				k, v = line.split('=')
				k=k.strip()
				v=v.strip()
				if k == location:
					uri = v
		return uri
		
	def run(self, args):
		parser = OptionParser(usage='%prog [location] [options]')
		parser.add_option('-l', '--uri', type='string', dest='location',
			metavar='URI', help='Set the URI for the chosen location')
		parser.add_option('--exclude', type='string', dest='exclude',
			metavar='RULE', help='Add an exclude rule (glob syntax)')
		parser.add_option('-d', '--dir', type='string', dest='dir',
			help="Work in DIR instead of the current directory")
		parser.add_option('-f', '--full', action='store_true', dest='force_full',
			help="Ignore the remote digest and force full upload")
		parser.add_option('-n', '--dry-run', action='store_true', dest='dry_run',
			help="Perform a trial run and make no changes")
		parser.add_option('--mark-updated', action='store_const', dest='dry_run', const='digest-only',
			help="Update the remote digest without syncing files. Use only if remote dir is known to be in sync")
		(options, args) = parser.parse_args(args)
		
		if options.dir:
			self.path = options.dir.rstrip('/')
		
		if options.exclude:
			print "Added exclude rule"
			self.add_exclude_rule(options.exclude)
			return
			
		if len(args):
			location = args[0]
		else:
			location = 'default'
		
		if options.location:
			self.add_location(location, options.location)
			print "Added location %s"%location
		
		uri = self.read_config(location)
					
		if not uri:
			print "Unknown location '%s'. Add with `tinyupload %s --location <uri>`"%(location, location)
			return
		
		backend = backend_from_uri(uri)
		self.sync(backend, options.dry_run, options.force_full)
		
		
if __name__ == '__main__':	
	t = TinyUpload()
	t.run(sys.argv[1:])
